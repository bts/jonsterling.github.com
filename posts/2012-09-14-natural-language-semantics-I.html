<!DOCTYPE html>
<html>
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8" />
<meta name="readability-verification" content="cG3MqZcEVveKZ6mnEFkePAL3Ug79Jxxp5Fn27CM7" />
<title>JS ⊢ Natural Language Semantics: Montague → Martin-Löf</title>
<link rel="stylesheet" type="text/css" href="../css/screen.css" />
<link rel="stylesheet" type="text/css" href="../css/syntax.css" />
<link rel="stylesheet" type="text/css" href="../css/coqdoc.css" />
<style type="text/css">
    @import url(http://nmashton.ca/css/gloss-0.0.1.css);
</style>
<script type="text/javascript" src="http://code.jquery.com/jquery-1.8.3.min.js"></script>
<script type="text/javascript" src="http://nmashton.ca/js/gloss-0.0.1.js"></script>
<link rel="alternate" type="application/rss+xml" title="Jonathan Sterling" href="../rss.xml" />


<!--[if IE]>
  <script src="http://html5shiv.googlecode.com/svn/trunk/html5.js"></script><![endif]-->
<!--[if lte IE 7]>
  <script src="js/IE8.js" type="text/javascript"></script><![endif]-->
<!--[if lt IE 7]>
<link rel="stylesheet" type="text/css" media="all" href="css/ie6.css"/><![endif]-->

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  'HTML-CSS': {
    availableFonts: [],
    webFont: 'TeX',
  },
  TeX: {
    Macros: {
      gk: ["\\style{font-family:Junicode!important; font-size:1.3em;}{\\text{#1}}", 1]
    }
  }
});
</script>
</head>
<body>

<header>
<h1><a href="../index.html"><span class="title">Natural Language Semantics: Montague → Martin-Löf.</span></a></h1>
</header>

<section class="post">
<article><p>My great joy at finally taking logical semantics for natural language at Berkeley was a bit dampened by the realization that everyone is still doing semantics in a type theory from the 1940s. Rather than wallowing in dismay, I have been inspired to think about manifesting semantics in a modern Constructive theory within the Martin-Löf tradition;<sup><a href="#fn1" class="footnoteRef" id="fnref1">1</a></sup> this is the first in a series of posts in that vein.</p>
<!--more-->

<h2 id="basics-the-sadly-typed-lambda-calculus">Basics: The Sadly Typed Lambda Calculus</h2>
<p>NL-semantics in the Montague tradition is typically done within a simply-typed lambda calculus, combined with some fast-and-loose subset-predicate stuff. I’ll try to avoid the nasty bits and just show you the context you need in order to understand what we’re doing. Let’s draw out the grammar and typing rules:</p>
<p><span class="math">\[\begin{align}
\text{types} &amp;::= e,\ t,\ \langle \text{type}, \text{type} \rangle
\tag{Grammar}\\
\text{connectives} &amp;::= \forall,\ \exists,\ \land,\ \lor,\ \lnot\\
\text{operators} &amp;::= \lambda,\ \iota
\end{align}\]</span></p>
<blockquote>
<p><span class="math">\(e\)</span> is the type of entities, and <span class="math">\(t\)</span> is the type of propositions; <span class="math">\(\langle e,t\rangle\)</span> is a function from entities to propositions. Function types are written thus in angle-brackets as comma-separated lists of types, with the comma associating to the right. <span class="math">\(\lambda\)</span> is the primative abstraction operator, and <span class="math">\(\iota\)</span> is the primitive singleton-inference operator.</p>
</blockquote>
<p>In extensional semantics, <span class="math">\(t\)</span> is just a truth value; in an intensional theory (which would seem to be necessary for reasons including the existence of hypotheticals and mood in language), <span class="math">\(t\)</span> can be thought of as the set of all worlds in which some proposition holds true.</p>
<p>Typing rules are pretty straight-forward, given a context of type-assumptions <span class="math">\(\Gamma\)</span> (basically a list of values and their types).</p>
<p><span class="math">\[\begin{align}
\frac{\Gamma, x:\sigma \vdash M:\tau}
     {\Gamma \vdash \lambda x.M : \langle\sigma,\tau\rangle}
\tag{T-abstraction}
\end{align}\]</span></p>
<blockquote>
<p>For some <span class="math">\(x:\sigma\)</span> and <span class="math">\(M:\tau\)</span> (where the body of <span class="math">\(M\)</span> may contain <span class="math">\(x\)</span>), the lambda abstraction <span class="math">\(\lambda x.M\)</span> is a function of type <span class="math">\(\langle\sigma,\tau\rangle\)</span>.</p>
</blockquote>
<p><span class="math">\[\begin{align}
\frac{\Gamma, f : \langle\sigma,\tau\rangle \vdash x : \sigma}
     {\Gamma \vdash f(x) : \tau}
\tag{T-application}
\end{align}\]</span></p>
<blockquote>
<p>The application of a function <span class="math">\(f:\langle\sigma,\tau\rangle\)</span> on a value <span class="math">\(x:\sigma\)</span> is <span class="math">\(f(x):\tau\)</span>.</p>
</blockquote>
<p><span class="math">\[\begin{align}
\frac{\Gamma, x:e \vdash P : \langle e,t\rangle}
     {\Gamma\vdash \iota x.P(x) : e}
\tag{T-inference}
\end{align}\]</span></p>
<blockquote>
<p>For a predicate <span class="math">\(P:\langle e,t\rangle\)</span> which is satisfied by only one entity, the inference <span class="math">\(\iota x.P(x)\)</span> is that entity.</p>
</blockquote>
<p>So under this framework, common nouns, adjectives and intransitive verbs are of type <span class="math">\(\langle e,t\rangle\)</span>, whereas individuals (like “Tucker” and 42) are of type <span class="math">\(e\)</span>. The <span class="math">\(\iota\)</span>-operator is used to map these <span class="math">\(\langle e,t\rangle\)</span> predicates to the contextually relevant value; if there are multiple (or zero) values in context that satisfy <span class="math">\(P\)</span>, the derivation of <span class="math">\(\iota x. P(x)\)</span> will crash. So, the following are logical representations of words and phrases in this framework:</p>
<p><span class="math">\[\begin{align}
⟦\text{dog}⟧ &amp;= \lambda x.\ \text{‘}x \text{ is a dog’} &amp;&amp;: \langle e,t\rangle\\
⟦\text{the}⟧ &amp;= \lambda P. \iota x. P(x) &amp;&amp;: \langle\langle e,t\rangle,e\rangle\\
⟦\text{the}⟧(⟦\text{dog}⟧) &amp;= \iota x.\ ⟦\text{dog}⟧(x)&amp;&amp;: e\\
⟦\text{love}⟧ &amp;= \lambda x. \lambda y.\ \text{‘}y \text{ loves } x\text{’} &amp;&amp;: \langle e,e,t\rangle
\end{align}\]</span></p>
<p>And so forth. In this representation, note that we define primitive predicates using an existing token in the metalanguage (in this case, English); it could have Greek or Latin.</p>
<h2 id="semantics-in-a-modern-tt-shifted-up-a-level">Semantics in a Modern TT: Shifted Up a Level</h2>
<p>In modern type theory, we have to sort of rejigger things a bit. The new world order is that simple nouns (formerly <span class="math">\(\langle e,t\rangle\)</span>) are actually just types; so, rather than saying <span class="math">\(⟦\text{dog}⟧(x)\)</span>, we now say <span class="math">\(x:⟦\text{dog}⟧\)</span>. We’ve actually hoisted most of our machinery into the type-level; under the Curry-Howard Correspondence, types are propositions, and terms are proofs of those propositions.</p>
<p>In our intensional interpretation of natural language semantics, then, different proofs will exist in different worlds; so, in all worlds, there is a proposition <span class="math">\(P\)</span>, but it will be provable in only some subset of worlds. So, to interpret the truth-value of a <span class="math">\(P\)</span> in some world, we are really trying to see if there exists a term of type <span class="math">\(P\)</span> in that world. In a later post, I’ll talk about ways that we can express the concept of multiple worlds in the new framework.</p>
<p>Actual predicates are types indexed by values (so-called <span class="math">\(\prod\)</span>-types); values of a predicate type are proofs that the saturated predicate (proposition) holds. Modification of predicates (as in “heavy book”) is done using <span class="math">\(\sum\)</span>-types.<sup><a href="#fn2" class="footnoteRef" id="fnref2">2</a></sup></p>
<p>To avoid getting mired in words, we can very simply encode this in <a href="http://wiki.portal.chalmers.se/agda/pmwiki.php">Agda</a>, a dependently-typed programming language with a few features that will prove very useful to us.</p>
<h2 id="agda-lets-formalize-our-semantics">Agda: Let’s Formalize Our Semantics</h2>
<p>Today, we’ll only show how to represent what we have currently demonstrated for the Montague-style theory. For those of you who don’t have much programming experience (let alone experience with Agda), I’ll try to leave helpful comments as we go. Let’s get started!</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell"><span class="kw">module</span> <span class="dt">Semantics</span> <span class="kw">where</span></code></pre>
<p>We have a type for cats; in this context, there is only one cat. We’ll be using <code>⟦double-brackets⟧</code> for values which are referring to a word or phrase.</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  <span class="kw">data</span> ⟦cat⟧ <span class="fu">:</span> <span class="dt">Set</span> <span class="kw">where</span>
    ⟦Emma⟧ <span class="fu">:</span> ⟦cat⟧</code></pre>
<p>Our first order of business is to show how we can derive “the”.</p>
<p>First, we need to define propositional equality. Agda’s standard library actually has this built-in, but we’ll define it for ourselves so that we can see how it works.</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  <span class="kw">data</span> _≡_ {<span class="dt">A</span> <span class="fu">:</span> <span class="dt">Set</span>} <span class="fu">:</span> <span class="dt">A</span> <span class="ot">→</span> <span class="dt">A</span> <span class="ot">→</span> <span class="dt">Set</span> <span class="kw">where</span>
    refl <span class="fu">:</span> {x <span class="fu">:</span> <span class="dt">A</span>} <span class="ot">→</span> x ≡ x</code></pre>
<p>The <span class="math">\(ι\)</span> operator can be seen as a proposition that for some proposition <span class="math">\(P\)</span>, there is one-and-only-one proof (or, in other words, only one term inhabits type <span class="math">\(P\)</span>).</p>
<p>A proof that a set <span class="math">\(P\)</span> is singleton would consist of the single proof <span class="math">\(x\)</span>, and a proof that all proofs of <span class="math">\(P\)</span> are equal to <span class="math">\(x\)</span>; that’s a pair, in which the second item (a function from a value to a proof that it is unique in some set <span class="math">\(P\)</span>) is dependent upon the first item, which is the value which we’re trying to prove is the only inhabitant of <span class="math">\(P\)</span>. This is a perfect use for a <span class="math">\(\sum\)</span>-type! Let’s define what that is:</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  record ∑ (<span class="dt">A</span> <span class="fu">:</span> <span class="dt">Set</span>) (<span class="dt">B</span> <span class="fu">:</span> <span class="dt">A</span> <span class="ot">→</span> <span class="dt">Set</span>) <span class="fu">:</span> <span class="dt">Set1</span> <span class="kw">where</span>
    constructor _,_
    field
      <span class="fu">fst</span> <span class="fu">:</span> <span class="dt">A</span>
      <span class="fu">snd</span> <span class="fu">:</span> <span class="dt">B</span> <span class="fu">fst</span></code></pre>
<p>We can define some syntactic sugar to make this a little easier to use:</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  syntax ∑ <span class="dt">A</span> (λ x <span class="ot">→</span> <span class="dt">B</span>) <span class="fu">=</span> ∑[ x ∶ <span class="dt">A</span> ] <span class="dt">B</span></code></pre>
<p>And so, a singleton-proof is just a specific instantiation of <span class="math">\(\sum\)</span>:</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  <span class="dt">Singleton</span> <span class="fu">:</span> <span class="dt">Set</span> <span class="ot">→</span> <span class="dt">Set1</span>
  <span class="dt">Singleton</span> <span class="dt">P</span> <span class="fu">=</span>  ∑[ x ∶ <span class="dt">P</span> ] (<span class="ot">∀</span> y <span class="ot">→</span> y ≡ x)</code></pre>
<blockquote>
<p>“For some proof <span class="math">\(x\)</span> of <span class="math">\(P\)</span>, every proof <span class="math">\(y\)</span> of <span class="math">\(P\)</span> is equal to <span class="math">\(x\)</span>.” In other words, <span class="math">\(x\)</span> is the only proof of <span class="math">\(P\)</span>.</p>
</blockquote>
<p>Using the <code>_,_</code> constructor from <span class="math">\(\sum\)</span>, we can make a proof that <code>⟦cat⟧</code> is a singleton set:</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  cat<span class="fu">-</span>singleton <span class="fu">:</span> <span class="dt">Singleton</span> ⟦cat⟧
  cat<span class="fu">-</span>singleton <span class="fu">=</span> ⟦Emma⟧ , λ { ⟦Emma⟧ <span class="ot">→</span> refl }</code></pre>
<p>We now have enough machinery to define the ι operator. Because we want to <em>infer</em> the proof that <code>P</code> is a singleton, we place that parameter in double-curly-braces; this is called an “instance argument” in Agda. If we did not do this, we would have to provide a proof that <code>P</code> is a singleton with every use of ι.</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  ι <span class="fu">:</span> (<span class="dt">P</span> <span class="fu">:</span> <span class="dt">Set</span>) <span class="ot">→</span> {{proof <span class="fu">:</span> <span class="dt">Singleton</span> <span class="dt">P</span>}} <span class="ot">→</span> <span class="dt">P</span>
  ι _ {{x , _}} <span class="fu">=</span> x</code></pre>
<p><!--_--></p>
<p>It turns out that <code>⟦the⟧</code> is actually the exact same thing as <span class="math">\(\iota\)</span>!</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  ⟦the⟧ <span class="fu">:</span> (<span class="dt">P</span> <span class="fu">:</span> <span class="dt">Set</span>) <span class="ot">→</span> {{proof <span class="fu">:</span> <span class="dt">Singleton</span> <span class="dt">P</span>}} <span class="ot">→</span> <span class="dt">P</span>
  ⟦the⟧ <span class="fu">=</span> ι</code></pre>
<p>And now, to let all our hard work pay off, we can show that ⟦the⟧ really does work as we had hoped!</p>
<pre class="sourceCode Haskell"><code class="sourceCode haskell">  ⟦the<span class="fu">-</span>cat⟧ <span class="fu">:</span> ⟦cat⟧
  ⟦the<span class="fu">-</span>cat⟧ <span class="fu">=</span> ⟦the⟧ ⟦cat⟧</code></pre>
<p>If <code>⟦cat⟧</code> had been inhabited by more values, the program would have failed to typecheck (since it would have been impossible to construct a proof that <code>⟦cat⟧</code> is a singleton).</p>
<h2 id="next-steps">Next steps</h2>
<p>Some things that still need to be discussed in a future post:</p>
<ol style="list-style-type: decimal">
<li><p>How can we unify our new view of semantics with the possible-worlds interpretation? How can we assert a “world-signature” (that says what kind of types and propositions we have), but allow the specific available theorems to differ from world-to-world?</p></li>
<li><p>How can we coerce a function of a more general type to a more specific type? For instance, “eat” might be represented by a type: <code>⟦animal⟧ → ⟦food⟧ → Set</code>, but it should be possible to treat it as a function <code>⟦cat⟧ → ⟦tuna⟧ → Set</code>. (For more on this, see Luo’s paper in the notes.)</p></li>
</ol>
<div class="footnotes">
<hr />
<ol>
<li id="fn1"><p>After I’d written this, I came across this awesome little paper, <a href="http://www.cs.rhul.ac.uk/~zhaohui/SALT20.pdf">Type-theoretical semantics with coercive subtyping</a> that, in addition to making a pretty convincing case for subtyping in the type theories used to encode formal semantics, also explains quite nicely some of the elementaries which I may gloss over; if you have no background in modern Type Theory, I suggest you read over at least Section 2. Note that my technique differs from that described in the paper, in that I do not have a separate kind <code>Prop</code> from <code>Set</code> (which is the type of small types).<a href="#fnref1">↩</a></p></li>
<li id="fn2"><p>I hate to toot on my own horn, but if you need to read up on <span class="math">\(\prod\)</span> and <span class="math">\(\sum\)</span>-types, I have written a <a href="http://www.jonmsterling.com/posts/2012-09-07-pi-is-for-power-sigma-for-product.html">few</a> <a href="http://www.jonmsterling.com/posts/2012-09-08-adding-universe-polymorphism.html">things</a> about those previously that may be helpful.<a href="#fnref2">↩</a></p></li>
</ol>
</div></article>
<h1>Want to comment?</h1>
<p> I’m @jonsterling on <a href="http://www.twitter.com/jonsterling">Twitter</a> and <a href="https://alpha.app.net/jonsterling">App.net</a>.</p>


<script src="//static.getclicky.com/js" type="text/javascript"></script>
<script type="text/javascript">try{ clicky.init(66625087);
    }catch(e){}</script>
<noscript><p><img alt="Clicky" width="1" height="1" src="//in.getclicky.com/66625087ns.gif" /></p></noscript>

<a rel="me" href="http://twitter.com/jonsterling"></a>
<a rel="me" href="https://alpha.app.net/jonsterling"></a>
</body>
</html>

